{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 500\n",
    "initial_state = np.array([-2,2])\n",
    "\n",
    "def rosenbrock(tensor):\n",
    "  x, y = tensor\n",
    "  return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2\n",
    "\n",
    "def training_function(config):\n",
    "  x = torch.Tensor(initial_state).requires_grad_(True)\n",
    "  steps = np.zeros((2, max_iterations))\n",
    "  steps[:, 0] = np.array(initial_state)\n",
    "  optimizer = optim.SGD(\n",
    "    [x], \n",
    "    lr = config[\"learning_rate\"], \n",
    "    momentum = config[\"momentum\"], \n",
    "    weight_decay = config[\"weight_decay\"]\n",
    "  )\n",
    "  for i in range(0, max_iterations):\n",
    "      optimizer.zero_grad()\n",
    "      f = rosenbrock(x)\n",
    "      f.backward(create_graph=True, retain_graph=True)\n",
    "      torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "      optimizer.step()\n",
    "      steps[:, i] = x.detach().numpy()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(pid=32378)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32378)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32377)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32377)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32376)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32376)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32380)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32380)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32374)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32374)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32381)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32381)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32382)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32382)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32368)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32368)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32372)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32372)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32373)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32373)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32379)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32379)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32375)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32375)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32370)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32370)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32369)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32369)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32371)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32371)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "\u001b[2m\u001b[36m(pid=32367)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32367)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "2021-11-21 00:00:13,442\tWARNING util.py:165 -- Processing trial results took 0.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:13,443\tWARNING util.py:165 -- The `process_trial` operation took 0.957 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "2021-11-21 00:00:14,309\tWARNING util.py:165 -- Processing trial results took 0.854 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:14,311\tWARNING util.py:165 -- The `process_trial` operation took 0.859 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/johnbjohn/.local/lib/python3.9/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(pid=32763)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=32763)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "2021-11-21 00:00:15,220\tWARNING util.py:165 -- Processing trial results took 0.900 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:15,221\tWARNING util.py:165 -- The `process_trial` operation took 0.903 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=317)\u001b[0m /home/johnbjohn/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "\u001b[2m\u001b[36m(pid=317)\u001b[0m   Variable._execution_engine.run_backward(\n",
      "2021-11-21 00:00:16,058\tWARNING util.py:165 -- Processing trial results took 0.833 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:16,059\tWARNING util.py:165 -- The `process_trial` operation took 0.836 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:16,846\tWARNING util.py:165 -- Processing trial results took 0.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:16,847\tWARNING util.py:165 -- The `process_trial` operation took 0.786 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:17,678\tWARNING util.py:165 -- Processing trial results took 0.827 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:17,680\tWARNING util.py:165 -- The `process_trial` operation took 0.832 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:18,485\tWARNING util.py:165 -- Processing trial results took 0.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:18,486\tWARNING util.py:165 -- The `process_trial` operation took 0.804 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:19,281\tWARNING util.py:165 -- Processing trial results took 0.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:19,282\tWARNING util.py:165 -- The `process_trial` operation took 0.794 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:20,057\tWARNING util.py:165 -- Processing trial results took 0.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:20,057\tWARNING util.py:165 -- The `process_trial` operation took 0.772 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:20,869\tWARNING util.py:165 -- Processing trial results took 0.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:20,870\tWARNING util.py:165 -- The `process_trial` operation took 0.785 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:21,612\tWARNING util.py:165 -- Processing trial results took 0.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:21,613\tWARNING util.py:165 -- The `process_trial` operation took 0.741 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:22,370\tWARNING util.py:165 -- Processing trial results took 0.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:22,371\tWARNING util.py:165 -- The `process_trial` operation took 0.757 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:23,139\tWARNING util.py:165 -- Processing trial results took 0.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:23,140\tWARNING util.py:165 -- The `process_trial` operation took 0.766 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:23,888\tWARNING util.py:165 -- Processing trial results took 0.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:23,889\tWARNING util.py:165 -- The `process_trial` operation took 0.748 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:24,651\tWARNING util.py:165 -- Processing trial results took 0.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:24,653\tWARNING util.py:165 -- The `process_trial` operation took 0.761 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:25,385\tWARNING util.py:165 -- Processing trial results took 0.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:25,386\tWARNING util.py:165 -- The `process_trial` operation took 0.732 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:26,129\tWARNING util.py:165 -- Processing trial results took 0.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:26,130\tWARNING util.py:165 -- The `process_trial` operation took 0.742 s, which may be a performance bottleneck.\n",
      "2021-11-21 00:00:26,851\tWARNING util.py:165 -- Processing trial results took 0.715 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-11-21 00:00:26,852\tWARNING util.py:165 -- The `process_trial` operation took 0.720 s, which may be a performance bottleneck.\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "  training_function,\n",
    "  config={\n",
    "      \"learning_rate\": tune.grid_search([0.001, 0.01, 0.1]),\n",
    "      \"momentum\": tune.grid_search([0.7, 0.8, 0.9]),\n",
    "      \"weight_decay\": tune.grid_search([0.1, 0])\n",
    "  },\n",
    "  verbose = 0\n",
    ")\n",
    "df = analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31333/1034547947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'experiment_tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row['loss'] <= 0.01:\n",
    "        print(row['loss'], row['experiment_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6165, requires_grad=True) 0_learning_rate=0.001,momentum=0.7,weight_decay=0.1\n",
      "tensor(0.0901, requires_grad=True) 1_learning_rate=0.01,momentum=0.7,weight_decay=0.1\n",
      "tensor(2.7362, requires_grad=True) 2_learning_rate=0.1,momentum=0.7,weight_decay=0.1\n",
      "tensor(1.9423, requires_grad=True) 3_learning_rate=0.001,momentum=0.8,weight_decay=0.1\n",
      "tensor(0.0512, requires_grad=True) 4_learning_rate=0.01,momentum=0.8,weight_decay=0.1\n",
      "tensor(3.3959, requires_grad=True) 5_learning_rate=0.1,momentum=0.8,weight_decay=0.1\n",
      "tensor(0.0584, requires_grad=True) 6_learning_rate=0.001,momentum=0.9,weight_decay=0.1\n",
      "tensor(0.0730, requires_grad=True) 7_learning_rate=0.01,momentum=0.9,weight_decay=0.1\n",
      "tensor(0.8251, requires_grad=True) 8_learning_rate=0.1,momentum=0.9,weight_decay=0.1\n",
      "tensor(4.2894, requires_grad=True) 9_learning_rate=0.001,momentum=0.7,weight_decay=0\n",
      "tensor(0.0092, requires_grad=True) 10_learning_rate=0.01,momentum=0.7,weight_decay=0\n",
      "tensor(0.7184, requires_grad=True) 11_learning_rate=0.1,momentum=0.7,weight_decay=0\n",
      "tensor(2.8692, requires_grad=True) 12_learning_rate=0.001,momentum=0.8,weight_decay=0\n",
      "tensor(0.0230, requires_grad=True) 13_learning_rate=0.01,momentum=0.8,weight_decay=0\n",
      "tensor(1.4711, requires_grad=True) 14_learning_rate=0.1,momentum=0.8,weight_decay=0\n",
      "tensor(0.0978, requires_grad=True) 15_learning_rate=0.001,momentum=0.9,weight_decay=0\n",
      "tensor(0.0498, requires_grad=True) 16_learning_rate=0.01,momentum=0.9,weight_decay=0\n",
      "tensor(0.9826, requires_grad=True) 17_learning_rate=0.1,momentum=0.9,weight_decay=0\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row['loss'], row['experiment_tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00d27791cbe9760abbfbdce3071a02bfdba14c2e9d904727a62f2dd0ef1861ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
